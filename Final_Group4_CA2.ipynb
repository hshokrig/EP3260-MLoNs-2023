{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_yJWxuX7PkTa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import resource\n",
        "from pathlib import Path\n",
        "\n",
        "giturl1 = 'https://raw.githubusercontent.com/vnmo/MLon/main/CA1_1c_greenhouse_cleanedData_part1.csv'\n",
        "giturl2 = 'https://raw.githubusercontent.com/vnmo/MLon/main/CA1_1c_greenhouse_cleanedData_part2.csv'\n",
        "data1  = pd.read_csv(giturl1)\n",
        "data2  = pd.read_csv(giturl2)  \n",
        "data_complete = pd.concat([data1,data2],ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data_complete.T\n",
        "print(f\"Size of Input data = {data.shape}\\n\")\n",
        "data=data.to_numpy()\n",
        "\n",
        "X_train = data[0:5231,0:1500]\n",
        "X_test = data[0:5231,1500:2921]\n",
        "\n",
        "Y_train = data[5231:5232,0:1500]\n",
        "Y_test = data[5231:5232,1500:2921]\n",
        "\n",
        "# X_train=X_train.to_numpy()\n",
        "# X_test=X_test.to_numpy()\n",
        "# Y_train=Y_train.to_numpy()\n",
        "# Y_test=Y_test.to_numpy()\n",
        "\n",
        "print(f\"Size of Input Training data = {X_train.shape}\")\n",
        "print(f\"Size of Output Training data = {Y_train.shape}\")\n",
        "print(f\"Size of Input Test data = {X_test.shape}\")\n",
        "print(f\"Size of Output Test data = {Y_test.shape}\")"
      ],
      "metadata": {
        "id": "doXQ8S8YnDZw",
        "outputId": "af115938-89af-44a3-b13b-cd2b0a2eb213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Input data = (5232, 2921)\n",
            "\n",
            "Size of Input Training data = (5231, 1500)\n",
            "Size of Output Training data = (1, 1500)\n",
            "Size of Input Test data = (5231, 1421)\n",
            "Size of Output Test data = (1, 1421)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the cost function using: \n",
        "$ f_i(w) = log(1 + \\exp( -y_iw^‚ä§x_i)) + 2*||w||^2$<br>\n",
        "\n",
        "Calculating the gradient of $f_i(w)$ using:\n",
        "\\begin{align}\n",
        "\\nabla f_i =(\\frac{1}{N}\\sum_{i\\in[N]}\\frac{-y_i *e^{-y_i w^T x_i}}{e^{-y_i w^T x_i}+1}x_i + 2\\lambda w)\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "KfD8bejZilT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV131sOMPkTe",
        "outputId": "be6948bf-d77b-4ca4-f9d9-5facb551fef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7336230.67442909]]\n",
            "[[2.4062520e-04]\n",
            " [2.4992540e-04]\n",
            " [2.4160600e-04]\n",
            " ...\n",
            " [4.8844600e-02]\n",
            " [1.6970608e+02]\n",
            " [7.6191000e+00]]\n"
          ]
        }
      ],
      "source": [
        "## Logistic ridge regression with different optimizers\n",
        "# cost function and gradient calculation\n",
        "\n",
        "def cost(x,y,w,lambda_):  \n",
        "    #Send in properly shaped NUMPY arrays\n",
        "\n",
        "    D, N = x.shape\n",
        "    dy,ny = y.shape\n",
        "    dw,nw = w.shape\n",
        "    \n",
        "\n",
        "    value = 0\n",
        "    for i in range(N):     \n",
        "        exponent = np.exp(-y[0,i]*(w.T@x[:,i]))\n",
        "        value += np.log(1+exponent)\n",
        "    c = lambda_ * (w.T@w)\n",
        "    return value/N + c \n",
        "\n",
        "def function_gradient(x, y, w, lambda_):\n",
        "    #Send in properly shaped NUMPY arrays\n",
        "    D, N = x.shape\n",
        "    dy,ny = y.shape\n",
        "    dw,nw = w.shape  \n",
        "\n",
        "    if (dw!=D or nw!=1):\n",
        "      print(\"Dimension of w is not correct\")\n",
        "      return\n",
        "    if (dy!=1 or ny!=N):\n",
        "      print(\"Dimension of y is not correct\")\n",
        "      return\n",
        "\n",
        "\n",
        "    value = np.zeros((D, 1))\n",
        "    for i in range(N):\n",
        "      exponent = np.exp(-y[0,i]*(w.T@x[:,i]))\n",
        "      increment= (-1*y[0,i]) * (exponent/(1+exponent)) * (x[:,i]);\n",
        "      value += increment.reshape(D, 1)\n",
        "    delF = value/N + 2* lambda_ * w\n",
        "    return delF\n",
        "\n",
        "\n",
        "w = X_train[:,0:1]; ## TESTING with random w\n",
        "lambda_= 1\n",
        "c = cost(X_test,Y_test,w,lambda_)\n",
        "delF = function_gradient(X_test, Y_test, w, lambda_)\n",
        "print(c)\n",
        "print(delF)\n",
        "\n",
        "\n",
        "# print(c)\n",
        "#D = Y_train.shape\n",
        "#print(D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Oo2B2n-xPkTe"
      },
      "outputs": [],
      "source": [
        "## Define solvers: GD, SGD, SVRG and SAG. \n",
        "# Setting the values here:\n",
        "\n",
        "alpha = 0.5\n",
        "num_iters = 25\n",
        "lambda_ = 0.01\n",
        "epsilon = 0.0001\n",
        "# ---------------------- Complete the blank definitions: --------------------------------------\n",
        "\n",
        "def solver(x,y, w, alpha, num_iters , lambda_ , epsilon , optimizer = \"GD\",mem=False):\n",
        "    \n",
        "    D, N = x.shape\n",
        "    dy,ny=y.shape\n",
        "    dw,nw=w.shape  \n",
        "\n",
        "    if (dw!=D or nw!=1):\n",
        "      print(\"Dimension of w is not correct\")\n",
        "      return\n",
        "    if (dy!=1 or ny!=N):\n",
        "      print(\"Dimension of y is not correct\")\n",
        "      return\n",
        "    \n",
        "    \n",
        "    \n",
        "    if (optimizer == \"GD\") :\n",
        "        for i in range(num_iters):\n",
        "            # update the parameter w for GD here:\n",
        "\n",
        "            g = function_gradient(x, y, w, lambda_)\n",
        "            w = w - (alpha*g)\n",
        "            \n",
        "            if (i%10==0) and (mem):\n",
        "                usage=resource.getrusage(resource.RUSAGE_SELF)\n",
        "                print(\"mem for GD (mb):\", (usage[2]*resource.getpagesize())/1000000.0)\n",
        "            if np.linalg.norm(g) <= epsilon:\n",
        "                break\n",
        "            #print(w) \n",
        "\n",
        "    elif (optimizer == \"SGD\"):\n",
        "        for i in range(num_iters):\n",
        "            # Complete SGD here:\n",
        "            Num_Sam = int(np.random.rand() * x.shape[1])\n",
        "            while Num_Sam == 0:\n",
        "              Num_Sam = int(np.random.rand() * x.shape[1])\n",
        "\n",
        "            ind = np.arange(x.shape[1])[:Num_Sam]\n",
        "            g = function_gradient(x[:, ind], y[:, ind], w, lambda_)\n",
        "            w = w - alpha*g\n",
        "                \n",
        "            if (i%100==0) and (mem):\n",
        "                usage=resource.getrusage(resource.RUSAGE_SELF)     \n",
        "                loss = cost(x,y,w,lambda_)\n",
        "                print(i, loss)\n",
        "            if (np.linalg.norm(g) <= epsilon):\n",
        "                break\n",
        "\n",
        "\n",
        "    elif (optimizer == \"SVRG\"):\n",
        "        i = 0\n",
        "        J = 200\n",
        "        K = 50\n",
        "        for k in range(K):\n",
        "\n",
        "            g = function_gradient(x, y, w, lambda_)\n",
        "            w_old = w\n",
        "            \n",
        "            for j in range(J):\n",
        "              Num_Sam = int(np.random.rand() * x.shape[1])\n",
        "              while Num_Sam == 0:\n",
        "                Num_Sam = int(np.random.rand() * x.shape[1])\n",
        "               \n",
        "              ind = np.arange(x.shape[1])\n",
        "              np.random.shuffle(ind)\n",
        "              ind = ind[:Num_Sam]\n",
        "\n",
        "              stepA = function_gradient(x[:, ind], y[:, ind], w_old, lambda_)\n",
        "              stepB = function_gradient(x[:, ind], y[:, ind], w, lambda_)\n",
        "              stepC = g\n",
        "\n",
        "              w_old = w_old - alpha*(stepA - stepB + stepC)\n",
        "                \n",
        "            w = w_old\n",
        "            i = i+1\n",
        "\n",
        "            if (i%100==0) and (mem):\n",
        "                    usage=resource.getrusage(resource.RUSAGE_SELF)\n",
        "                    loss = cost(x,y,w,lambda_)\n",
        "                    print(i, loss)\n",
        "            if (np.linalg.norm((stepA - stepB + stepC)) <= epsilon):\n",
        "                break\n",
        "                \n",
        "\n",
        "    elif (optimizer == \"SAG\"):\n",
        "        Num_Sam = 5231\n",
        "        dw = np.zeros(w.shape)\n",
        "        gi = np.zeros(N, dy)\n",
        "\n",
        "\n",
        "        for i in range(num_iters):\n",
        "            ind = np.arange(x.shape[1])\n",
        "            np.random.shuffle(ind)\n",
        "            comb_ind = ind[:Num_Sam]\n",
        "\n",
        "            g = function_gradient(x[:, comb_ind].reshape(D, comb_ind.size), y[:, comb_ind].reshape(d, comb_ind.size), w, lambda_)\n",
        "            print(f\"g = {g.shape}\")\n",
        "            print(f\"gi = {gi.shape}\")\n",
        "            gi[comb_ind,:] = g\n",
        "            print(f\"gi = {gi.shape}\")\n",
        "\n",
        "            dw = np.sum(gi[:,:],axis=0)\n",
        "            w = w - alpha * dw/N\n",
        "            if (np.linalg.norm(dw/N) <= epsilon):\n",
        "                break\n",
        "\n",
        "            if (i%100==0) and (mem):\n",
        "                loss = cost(x,y,w,lambda_)\n",
        "                usage=resource.getrusage(resource.RUSAGE_SELF)\n",
        "                print(i, loss)\n",
        "        i=k\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "    return w       \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBv0P0LePkTf",
        "outputId": "e2672692-aac0-4d8e-86d8-87888dce9fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5231, 1)\n",
            "Weights of GD after convergence: \n",
            " [[0.00765498]\n",
            " [0.00579736]\n",
            " [0.00047369]\n",
            " ...\n",
            " [0.00390197]\n",
            " [0.00334771]\n",
            " [0.00013224]]\n",
            "Cost of GD after convergence:  [[0.00108435]]\n",
            "Training time for GD:  4.373081207275391  seconds\n",
            "Weights of SGD after convergence: \n",
            " [[0.00765498]\n",
            " [0.00579736]\n",
            " [0.00047369]\n",
            " ...\n",
            " [0.00391442]\n",
            " [0.00335827]\n",
            " [0.00016261]]\n",
            "Cost of SGD after convergence:  [[0.00111445]]\n",
            "Training time for SGD:  1.089224100112915  seconds\n",
            "Weights of SVRG after convergence: \n",
            " [[0.00765499]\n",
            " [0.00579736]\n",
            " [0.00047369]\n",
            " ...\n",
            " [0.00392598]\n",
            " [0.00336806]\n",
            " [0.00019077]]\n",
            "Cost of SVRG after convergence:  [[0.00114543]]\n",
            "Training time for SVRG:  1.2613723278045654  seconds\n",
            "Weights of SAG after convergence: \n",
            " [[0.00765498]\n",
            " [0.00579736]\n",
            " [0.00047369]\n",
            " ...\n",
            " [0.00391798]\n",
            " [0.00336128]\n",
            " [0.00017127]]\n",
            "Cost of SAG after convergence:  [[0.00112367]]\n",
            "Training time for SAG:  1.1732664108276367  seconds\n"
          ]
        }
      ],
      "source": [
        "## Solving the optimization problem:\n",
        "\n",
        "#y = np.array(Y_train.iloc[0:6000])\n",
        "#x = np.array(X_train.iloc[0:6000,:])\n",
        "\n",
        "#y = np.array(Y_train.iloc[0:6000])\n",
        "#x = np.array(X_train.iloc[0:6000,:])\n",
        "D,N = X_train.shape\n",
        "w = np.random.rand(D,1)*0.01\n",
        "\n",
        "D, N = X_train.shape\n",
        "d = 1\n",
        "#w = np.random.normal(0,0.1, D*d).reshape(D,d)\n",
        "#w = np.random.rand(D,1)*0.01 \n",
        "print(w.shape) # Initialization of w\n",
        "\n",
        "#-------------------- GD Solver -----------------------\n",
        "start=time.time()\n",
        "gde = solver(X_train, Y_train, w, alpha, num_iters, lambda_, epsilon, optimizer=\"GD\", mem=False)\n",
        "end = time.time()\n",
        "print(\"Weights of GD after convergence: \\n\",gde)\n",
        "\n",
        "cost_value = cost(X_test,Y_test,gde,lambda_)  # Calculate the cost value\n",
        "print(\"Cost of GD after convergence: \",cost_value)\n",
        "print(\"Training time for GD: \", end-start , ' seconds')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-------------------- SGD Solver -----------------------\n",
        "start=time.time()\n",
        "sgde = solver(X_train, Y_train, w, alpha, num_iters, lambda_, epsilon, optimizer=\"SGD\", mem=False)\n",
        "end = time.time()\n",
        "print(\"Weights of SGD after convergence: \\n\",sgde)\n",
        "\n",
        "cost_value = cost(X_test,Y_test,sgde,lambda_)  # Calculate the cost value\n",
        "print(\"Cost of SGD after convergence: \",cost_value)\n",
        "print(\"Training time for SGD: \", end-start , ' seconds')\n",
        "\n",
        "\n",
        "\n",
        "#-------------------- SVRG Solver -----------------------\n",
        "start=time.time()\n",
        "svrg = solver(X_train, Y_train, w, alpha, num_iters, lambda_, epsilon, optimizer=\"SGD\", mem=False)\n",
        "end = time.time()\n",
        "print(\"Weights of SVRG after convergence: \\n\",svrg)\n",
        "\n",
        "cost_value = cost(X_test,Y_test,svrg,lambda_)  # Calculate the cost value\n",
        "print(\"Cost of SVRG after convergence: \",cost_value)\n",
        "print(\"Training time for SVRG: \", end-start , ' seconds')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-------------------- SAG Solver -----------------------\n",
        "start=time.time()\n",
        "sag = solver(X_train, Y_train, w, alpha, num_iters, lambda_, epsilon, optimizer=\"SGD\", mem=False)\n",
        "end = time.time()\n",
        "print(\"Weights of SAG after convergence: \\n\",sag)\n",
        "\n",
        "cost_value = cost(X_test,Y_test,sag,lambda_)  # Calculate the cost value\n",
        "print(\"Cost of SAG after convergence: \",cost_value)\n",
        "print(\"Training time for SAG: \", end-start , ' seconds')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}