{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# (a) Find a closed-form solution for this problem\n",
        "\n",
        "The objective function is: $w^* = \\min_{w∈\\mathbb{R}} \\frac {1}{N} \\sum_{i\\in N}\\|w^Tx_i - y_i\\|^2+\\lambda\\|w\\|^2_2$\n",
        "\n",
        "The closed-form solution for this optimization problem is: $$w = (X^TX+N\\lambda I)^{-1}X^TY$$\n",
        "\n",
        "where $I$ is the identity matrix."
      ],
      "metadata": {
        "id": "Eow2PMwtF0Ic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gyprhByW3gXO"
      },
      "outputs": [],
      "source": [
        "##imports from libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE0atZsX3gXU"
      },
      "source": [
        "## (b) For “Individual household electric power consumption” dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2ln2qtm3gXX"
      },
      "outputs": [],
      "source": [
        "## Load data and preprocessing\n",
        "\n",
        "## Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip\"\n",
        "data = pd.read_csv(url, sep=\";\", low_memory=False, \n",
        "                 parse_dates={\"timestamp\":[\"Date\", \"Time\"]}, \n",
        "                 infer_datetime_format=True, index_col=\"timestamp\")\n",
        "\n",
        "# Preprocess the data\n",
        "data = data.dropna()\n",
        "data = data.astype(float)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "n = data.shape[0]\n",
        "train_ratio = 0.75\n",
        "train_index = int(n * train_ratio)\n",
        "X_train = data[[\"Global_reactive_power\",\"Voltage\",\"Global_intensity\"]][:train_index].to_numpy()\n",
        "y_train = data[[\"Global_active_power\"]][:train_index].to_numpy().ravel()\n",
        "X_test = data[[\"Global_reactive_power\",\"Voltage\",\"Global_intensity\"]][train_index:].to_numpy()\n",
        "y_test = data[[\"Global_active_power\"]][train_index:].to_numpy().ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JUnncoC3gXZ",
        "outputId": "39999ce8-1ebd-4842-fb2e-729122ca95d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.0018484036970121591\n",
            "Consumed Time in seconds: 0.11168336868286133\n",
            "Optimal Regressor: [-0.1899048   0.00404011  0.23987332]\n"
          ]
        }
      ],
      "source": [
        "## Closed form solution and optimal linear regressor\n",
        "\n",
        "# Define lambda here:\n",
        "lambd = 0.1 # change the value\n",
        "\n",
        "## Calculate the closed-form solution here:\n",
        "# def linear_ridge_regression(X, y, lambd):\n",
        "#     n, m = X.shape\n",
        "#     identity = np.identity(m)\n",
        "#     identity[0, 0] = 0\n",
        "#     w = np.linalg.inv(X.T @ X + lambd * identity) @ X.T @ y\n",
        "#     return w\n",
        "\n",
        "reg = linear_model.Ridge(alpha=lambd)\n",
        "start = time.time()\n",
        "## Find the optimal linear regressor here:\n",
        "# w = linear_ridge_regression(X_train, y_train, lambd)\n",
        "reg.fit(X_train, y_train)\n",
        "w = reg.coef_\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Evaluate the performance on the test set\n",
        "# y_pred = X_test @ w\n",
        "# mse = np.mean((y_test - y_pred) ** 2)\n",
        "# print(\"Mean squared error:\", mse)\n",
        "y_pred = reg.predict(X_test)\n",
        "mse = metrics.mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Consumed Time in seconds:\", end-start)\n",
        "print(\"Optimal Regressor:\", w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El7jQurw3gXb"
      },
      "source": [
        "## (c) For “Greenhouse gas observing network” dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oeQ-XKN-3gXd",
        "outputId": "2531eef5-7792-43a5-f42c-d1da20cb84ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=ff71998442e342c374ac95f4f4a115fc7b66e825831765e8e4ad052e8e024525\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "\n",
        "from numpy.random import multivariate_normal\n",
        "from scipy.linalg import toeplitz\n",
        "from numpy.random import randn\n",
        "\n",
        "import requests\n",
        "import csv\n",
        "import wget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00328/ghg_data.zip'\n",
        "file_name = 'datasetGHG'\n",
        "wget.download(url, file_name)\n",
        "!unzip datasetGHG"
      ],
      "metadata": {
        "id": "ZAMIvIeKRfe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read .dat to feature and label vectors\n",
        "'''    \n",
        "    X : `numpy.array`, shape=(n_samples, n_features)\n",
        "        The features matrix\n",
        "    y : `numpy.array`, shape=(n_samples, n_outputs)\n",
        "        The labels matrix\n",
        "'''\n",
        "N = 2921 # number of data \n",
        "d = int(5232/16*15) # number of features\n",
        "dy = int(5232/16) # number of outputs\n",
        "count = [\"%04d\" % x for x in range(1, N+1)]\n",
        "X = np.zeros((N, d))\n",
        "y = np.zeros((N, dy))\n",
        "for n in range(1, N+1):\n",
        "    datContent = [i.strip().split() for i in open(\"./ghg_data/ghg.gid.site{}.dat\".format(count[n-1])).readlines()]\n",
        "    X[n-1,:] = np.array(datContent[:15]).astype(float).reshape((-1))\n",
        "    y[n-1,:] = np.array(datContent[15]).astype(float)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckA8JGppRgS1",
        "outputId": "6fa06fb1-0086-4eac-a191-07c3517845bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2921, 4905)\n",
            "(2921, 327)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n, m = X.shape\n",
        "\n",
        "train_ratio = 0.8\n",
        "train_index = int(n * train_ratio)\n",
        "X_train = X[:train_index]\n",
        "y_train = y[:train_index]\n",
        "X_test = X[train_index:]\n",
        "y_test = y[train_index:]"
      ],
      "metadata": {
        "id": "IbbRg2Y-Rjpm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define lambda here:\n",
        "lambd = 0.1 # change the value\n",
        "\n",
        "# Calculate the closed-form solution here:\n",
        "def linear_ridge_regression(X, y, lambd):\n",
        "    n, m = X.shape\n",
        "    w = np.linalg.inv(X.T @ X + lambd * np.identity(m)) @ X.T @ y\n",
        "    return w\n",
        "\n",
        "reg = linear_model.Ridge(alpha=lambd)\n",
        "start = time.time()\n",
        "# Find the optimal linear regressor here:\n",
        "w1 = linear_ridge_regression(X_train, y_train, lambd)\n",
        "reg.fit(X_train, y_train)\n",
        "w2 = reg.coef_\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Evaluate the performance on the test set\n",
        "y_pred1 = X_test @ w1\n",
        "y_pred2 = reg.predict(X_test)\n",
        "mse1 = np.mean((y_test - y_pred1) ** 2)\n",
        "mse2 = np.mean((y_test - y_pred2) ** 2)\n",
        "print(\"Mean Squared Error:\", mse1)\n",
        "print(\"Mean Squared Error:\", mse2)\n",
        "print(\"Consumed Time in seconds:\", end-start)\n",
        "print(\"Optimal Regressor:\", w1)\n",
        "print(\"Optimal Regressor:\", w2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8L8IppVRl9a",
        "outputId": "630c0efc-bc9d-423a-f335-5b8f9299d6e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 78563.38866984137\n",
            "Mean Squared Error: 81864.41059090091\n",
            "Consumed Time in seconds: 14.252393245697021\n",
            "Optimal Regressor: [[-1.34424906e-01 -1.39461914e-01 -1.38639972e-01 ... -3.57860393e-01\n",
            "  -4.45591855e-01 -6.69582966e-01]\n",
            " [ 4.72797279e-03 -1.17182496e-02 -2.62901689e-02 ... -2.09593741e-02\n",
            "  -3.16648816e-02 -7.41467648e-02]\n",
            " [ 2.78227387e-01  7.40226029e-02  1.69706704e-02 ...  1.09537850e-01\n",
            "  -3.10123876e-01  7.29959455e-02]\n",
            " ...\n",
            " [-2.41603239e+00 -8.89302727e-01  3.00106098e+00 ...  2.98104366e+00\n",
            "  -2.31228301e+00  5.26471446e+00]\n",
            " [-2.56668479e+00 -2.32272928e+00  1.01233516e+00 ...  3.06039113e+00\n",
            "   3.90717584e+00 -5.21008847e-02]\n",
            " [-2.34720888e-01  5.16715107e-01  1.63194143e-04 ...  2.84157762e-03\n",
            "  -3.59185574e+00 -1.26026889e+00]]\n",
            "Optimal Regressor: [[ 3.94074100e-04  1.76765028e-02  2.65691526e-01 ... -2.26227174e+00\n",
            "  -2.63778702e+00 -3.98327295e-01]\n",
            " [ 3.54619938e-04  6.35239273e-03  9.22494184e-02 ... -1.11892145e+00\n",
            "  -2.21654729e+00  7.61037890e-01]\n",
            " [-3.78104887e-04 -1.40097535e-02  6.06678056e-03 ...  3.12271032e+00\n",
            "   9.56082280e-01 -1.29275870e-01]\n",
            " ...\n",
            " [-4.10832601e-04  3.82747337e-03  1.06926143e-01 ...  3.02765875e+00\n",
            "   3.03883673e+00 -4.67575191e-02]\n",
            " [ 1.59909702e-04 -1.31234041e-02 -3.03677690e-01 ... -2.35641151e+00\n",
            "   3.92758364e+00 -3.54490036e+00]\n",
            " [-1.00071626e-04 -4.71104971e-02  9.28453901e-02 ...  5.09340958e+00\n",
            "   2.71173832e-02 -1.07799298e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (d) How would you address even bigger datasets?\n",
        "\n",
        "When handling big datasets, we should consider the iterative approaches with suitabe solver. The time complexity of iterative approaches depend on teh cost per iteration and the total number of iterations. The iteration costs of some solvers are linear to $N$ (the number of samples in the dataset), such as Gradient Descent, while some solvers' iteration costs are independent of $N$.\n",
        "\n",
        "For large datasets with high dimensional feature space, it is better to choose iterative appraoch instead of closed-form approach.\n",
        "\n",
        "Other approaches to address the scalability issues include: parallel computing, mini-batch learning, feature selection and dimension reduction."
      ],
      "metadata": {
        "id": "43kKwIrMLh9L"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}