{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CA 1"
      ],
      "metadata": {
        "id": "1z75PVKJFAHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.a Closed form solution of Ridge Regression\n",
        "We need to minimise \n",
        "\n",
        "$Min_w\\;\\left(\\frac{1}{N}\\sum_i||x_i^Tw-y_i||^2+\\lambda||w||^2\\right)$<br>\n",
        "$=Min_w\\;\\left(\\sum_i||x_i^Tw-y_i||^2+\\alpha||w||^2\\right)$, where $\\alpha = N\\lambda.$<br>\n",
        "\n",
        "$w^*=ArgMin_w\\,\\left(||w^TX-Y||^2+\\alpha||w||^2\\right)$, where $X=[x_1\\ x_2\\ ...],Y=[y_1\\ y_2\\ ...]$.\n",
        "<br> <br> Taking derivative w.r.t $w$ and equating it to zero gives\n",
        "\n",
        "$2X(w^⊤X-Y)^T+2\\alpha w=0$<br>\n",
        "$\\Rightarrow XX^Tw-XY^T+\\alpha wI=0$<br>\n",
        "$\\Rightarrow w^* =\\left(XX^T+\\alpha I\\right)^{-1}XY^T$<br>\n",
        "\n",
        "<br> If we assume an error variance of $\\sigma_1^2$ and a prior variance $\\sigma_2^2$, then $Nλ = \\alpha=\\sigma_1^2\\big/\\sigma_2^2$.  "
      ],
      "metadata": {
        "id": "foEgXLRHxM_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "## 1.b Household power dataset"
      ],
      "metadata": {
        "id": "-uvJNyKZZ-Ne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uFSWWmVEwnG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time as tm\n",
        "\n",
        "giturl = 'https://raw.githubusercontent.com/vnmo/MLon/main/CA1_1b_householdPower_cleanedData.csv'\n",
        "data  = pd.read_csv(giturl)\n",
        "\n",
        "# This is a cleaned data using MATLAB for easiness.\n",
        "# Date and Time are combined and converted to UNIX format\n",
        "##      --- one can subtract any date base from this if required to reduce the data range\n",
        "##      --- For example, lowest date time is 21/12/2006\t11:17:00. Subtract 1166289840 to make this zero\n",
        "##      --- Subtract  1164931200 to make the base to 01-Dec-2006 00:00:00\n",
        "##      --- Subtract  1136073600 to make the base to 01-Jan-2006 00:00:00\n",
        "# All NaNs and invalid cells are deleted.\n",
        "# Hence new size is 2049280 x 8\n",
        "#-----Attributes-----\n",
        "#           Date Time in UNIX format\n",
        "#           Active Power\n",
        "#           Reactive Power\n",
        "#           Voltage\n",
        "#           Global Intensity\n",
        "#           Submetering 1\n",
        "#           Submetering 2\n",
        "#           Submetering 3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take  Powers, voltage and intensity as input variable, i.e., x_i for i=1:N\n",
        "inputdata= data.iloc[:, [1, 2, 3, 4]]\n",
        "\n",
        "# Take all sub-meterings as output variable, i.e., y_i for i=1:N\n",
        "# Change if required\n",
        "outputdata=data.iloc[:,[5,6,7]]\n",
        "\n",
        "X=np.transpose(inputdata)\n",
        "Y=np.transpose(outputdata)\n",
        "print(f\"Size of input data = {X.shape}\")\n",
        "print(f\"Size of output data = {Y.shape}\")\n",
        "\n",
        "alpha = np.float32(2.0) # Lambda: Take a value\n",
        "p = len(X) # Dimension of data\n",
        "\n",
        "start = tm.time()\n",
        "# Find the regressor matrix (or vector) using the closed-form solution\n",
        "w_opt = np.linalg.inv((X@X.T) + alpha * np.eye(p)) @ (X@Y.T)\n",
        "stop = tm.time()\n",
        "\n",
        "print(f\"Regressor w=\\n {w_opt}\")\n",
        "totTime_1b = stop-start\n",
        "print(f\"\\nTotal time time taken to compute the closed form solution = {totTime_1b} seconds\")"
      ],
      "metadata": {
        "id": "anpHCYSMFHYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8fd6e6-fca3-496a-a5ee-ddd5e72e0327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of input data = (4, 2049280)\n",
            "Size of output data = (3, 2049280)\n",
            "Regressor w=\n",
            "    Sub_metering_1  Sub_metering_2  Sub_metering_3\n",
            "0      -14.082426      -14.391115       48.262268\n",
            "1       -3.114029       -1.534777        3.020558\n",
            "2       -0.007566       -0.005523        0.004318\n",
            "3        4.041872        4.004468      -10.296116\n",
            "\n",
            "Total time time taken to compute the closed form solution = 1.1671276092529297 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br> \n",
        "## 1.c Greenhouse dataset"
      ],
      "metadata": {
        "id": "nLQs_c5LaGQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time as tm\n",
        "\n",
        "giturl1 = 'https://raw.githubusercontent.com/vnmo/MLon/main/CA1_1c_greenhouse_cleanedData_part1.csv'\n",
        "giturl2 = 'https://raw.githubusercontent.com/vnmo/MLon/main/CA1_1c_greenhouse_cleanedData_part2.csv'\n",
        "data1  = pd.read_csv(giturl1)\n",
        "data2  = pd.read_csv(giturl2)  \n",
        "data = pd.concat([data1,data2],ignore_index=True)\n",
        "\n",
        "# This is a cleaned data using MATLAB for easiness.\n",
        "# Data is split into 4 parts due to github data restrictions"
      ],
      "metadata": {
        "id": "JcDvI8ekaOuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input variables (Change if required)\n",
        "inputAttributes = np.arange(0,5231)\n",
        "# Output variables (Change if required)\n",
        "outputAttributes = np.arange(5231,5232)\n",
        "\n",
        "inputdata=data.iloc[:,inputAttributes]\n",
        "outputdata=data.iloc[:,outputAttributes]\n",
        "X=np.transpose(inputdata)\n",
        "Y=np.transpose(outputdata)\n",
        "print(f\"Size of input data = {X.shape}\")\n",
        "print(f\"Size of output data = {Y.shape}\")\n",
        "\n",
        "alpha = np.float32(2.0) # Lambda: Take a value\n",
        "p = len(X) # Dimension of data\n",
        "\n",
        "start = tm.time()\n",
        "# Find the regressor matrix (or vector) using the closed-form solution\n",
        "w_opt = np.linalg.inv((X@X.T) + alpha * np.eye(p)) @ (X@Y.T)\n",
        "stop = tm.time()\n",
        "\n",
        "print(f\"Regressor w=\\n {w_opt}\")\n",
        "totTime_1c = stop-start\n",
        "print(f\"\\nTotal time time taken to compute the closed form solution = {totTime_1c} seconds\")\n"
      ],
      "metadata": {
        "id": "2F9HPVmdbmAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac9359b-b7f8-4d08-9d6c-650425155fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of input data = (5231, 2921)\n",
            "Size of output data = (1, 2921)\n",
            "Regressor w=\n",
            "           5231\n",
            "0    -0.102481\n",
            "1    -0.142095\n",
            "2     0.751174\n",
            "3    -0.521801\n",
            "4     0.258978\n",
            "...        ...\n",
            "5226 -1.081724\n",
            "5227  0.025382\n",
            "5228 -1.059141\n",
            "5229  1.886304\n",
            "5230  0.132544\n",
            "\n",
            "[5231 rows x 1 columns]\n",
            "\n",
            "Total time time taken to compute the closed form solution = 25.548195362091064 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is scalability issue and the time taken for second dataset is around $20$ to $1000$ times more than that of first dataset.\n"
      ],
      "metadata": {
        "id": "l3MJZz0e2j-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "## 1.d\n",
        "As is evident from $\\Rightarrow w^* =\\left(XX^T+\\alpha I\\right)^{-1}XY^T$<br> calculated above, this least sqaures problem becomes harder to compute as the matrices increase in size and become denser. Therefore, while linear regression offers a one step solution, because of being computationally expensive, iterative methods such as gradient descent need to be employed.\n"
      ],
      "metadata": {
        "id": "epqsPWdYxs03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HW 2\n",
        "\n",
        "## HW 2.1: Human Activity Recognition Using Smartphones dataset\n",
        "First dataset is cleaned by converting/combining Y labels to binary values as follows:\n",
        "*   $-1$ for walking (WALKING,WALKING UPSTAIRS,WALKING DOWNSTAIRS), and\n",
        "*   $1$ for not (SITTING,STANDING,LAYING).\n",
        "\n",
        "If $x_i$ are column vectors,<br>\n",
        "$Δf_i(w)=\\frac{-y_ie^{-y_iw^Tx_i}}{1+e^{-y_iw^Tx_i}}x_i$\n",
        "<br>$Δf(w)=\\frac{1}{N}\\underset{i\\in[N]}{\\sum}\\left(\\frac{-y_ie^{-y_iw^Tx_i}}{1+e^{-y_iw^Tx_i}}x_i\\right)+2\\lambda w$<br>\n",
        "\n",
        "$Δ^2f_i(w)=\\frac{y_i^2e^{-y_iw^Tx_i}}{(1+e^{-y_iw^Tx_i})^2}xx^T$\n",
        "<br>$Δ^2f(w)=\\frac{1}{N}\\underset{i\\in[N]}{\\sum}\\left(\\frac{y_i^2e^{-y_iw^Tx_i}}{(1+e^{-y_iw^Tx_i})^2}xx^T\\right)+2λ\\mathrm{I}$\n",
        "\n",
        "### 2.1 (a)\n",
        "The quadratic regulariser term of $f(w)$ is not Lipschitz continuous, hence $f(w)$ is also not Lipschitz continuous\n",
        "\n",
        "<!-- Since $xx^T\\succcurlyeq0,\\; Δ^2f_i(w)$ is PSD. $⇒$ Convex.\n",
        "\n",
        "Since $f$ is twice differentiable and convex, Lipschits constant is the maximum eigenvalue. Further, in ideal scenario, <br>$w^Tx_i=y_i\\quad⇒\\quadΔ^2f(w)=\\frac{1}{N}\\underset{i\\in[N]}{\\sum}\\left(\\frac{y_i^2e^{-y_i^2}}{(1+e^{-y_i^2})^2}xx^T\\right)+2λ\\mathrm{I}$\n",
        "\n",
        "From the dataset, maximum eigen value of $(Δ^2f(w)-2\\lambda I)$ is approximately $52$<br>\n",
        "Thus, a small Lipschitz constant is $\\boxed{B=2\\lambda+52}.$\n",
        "\n",
        "Note: Eigenvalues depends on $Y$. If $Y\\in\\{0,1\\}$ instead of $Y\\in\\{-1,1\\}$, then $B=2\\lambda+41$ -->\n",
        "\n",
        "<br><br>\n",
        "### 2.1 (b)\n",
        "Note that the gradient of $f_i$ is defined everywhere. Further, $\\Delta f_i$ is Lipschitz because $\\Delta^2 f_i$ is upperbounded. Hence $f_i$ is smooth.\n",
        "\n",
        "Smoothness constant L is the supremum of the Hessian. Also, in ideal scenario, $w^Tx_i=y_i$. Thus,<br>\n",
        "$L_i=Max \\left\\{\\frac{y_i^2e^{-y_i^2}}{(1+e^{-y_i^2})^2}x_ix_i^T\\right\\}=\\frac{1}{2}||x_i||^2$\n",
        "\n",
        "The function $f$ is also smooth because the gradient of the regulariser is defined everywhere and its hessian is a constant matrix.\n",
        "\n",
        "<br><br>\n",
        "### 2.1 (c)\n",
        "We have$Δ^2f_i(w)\\succ0,\\,\\forall x\\neq \\overset{\\rightarrow}{0}$ (Positive Definite).<br>\n",
        "Let $x_1=0\\neq x_2, g(x)=xx^T$\n",
        "<br>$\\Rightarrow g(px_1+(1-p)x_2)=g((1-p)x_2)=(1-p)^2x_2x_2^T$\n",
        "<br>$<(1-p)g(x_2)=p.0+(1-p)g(x_2)=pg(x_1)+(1-p)g(x_2)$\n",
        "<br> Thus $xx^T\\succ0$ for $x=\\overset{\\rightarrow}{0}$ as well.\n",
        "<br> ⇒ $Δ^2f_i(w)$ is positive definite ⇒ Strong convex.\n",
        "\n",
        "Since $f$ is the sum of $N$ strongly convex $f_i, i\\in[N]$, $f$ is also strongly convex.\n",
        "\n",
        "\n",
        "\n",
        "<br>Thus $\\mu=2\\lambda+\\text{Min.EigenValue of }\\left(\\frac{1}{N}\\underset{i\\in[N]}{\\sum}\\left(\\frac{y_i^2e^{-y_iw^Tx_i}}{(1+e^{-y_iw^Tx_i})^2}xx^T\\right)\\right)$, the second part of which can easily be found from the dataset\n",
        "\n",
        "$\\Rightarrow \\boxed{\\mu=2\\lambda+5\\times 10^{-15}}$\n",
        "\n",
        "Note: Eigenvalues depends on $Y$. If $Y\\in\\{0,1\\}$ instead of $Y\\in\\{-1,1\\}$, then $B=2\\lambda+3\\times 10^{-15}$"
      ],
      "metadata": {
        "id": "3UmHOKRcZJra"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}